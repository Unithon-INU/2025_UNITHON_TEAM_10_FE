{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7637e487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.130-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from ultralytics) (2.2.5)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from ultralytics) (3.10.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from ultralytics) (11.1.0)\n",
      "Collecting pyyaml>=5.3.1 (from ultralytics)\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting requests>=2.23.0 (from ultralytics)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from ultralytics) (1.15.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from ultralytics) (2.6.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from ultralytics) (0.21.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from ultralytics) (7.0.0)\n",
      "Collecting py-cpuinfo (from ultralytics)\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from ultralytics) (2.2.3)\n",
      "Collecting seaborn>=0.11.0 (from ultralytics)\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.23.0->ultralytics)\n",
      "  Downloading charset_normalizer-3.4.2-cp310-cp310-macosx_10_9_universal2.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.23.0->ultralytics)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.23.0->ultralytics)\n",
      "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.23.0->ultralytics)\n",
      "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: filelock in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
      "Requirement already satisfied: sympy!=1.13.2,>=1.13.1 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from sympy!=1.13.2,>=1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Downloading ultralytics-8.3.130-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.2-cp310-cp310-macosx_11_0_arm64.whl (171 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
      "Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "Downloading charset_normalizer-3.4.2-cp310-cp310-macosx_10_9_universal2.whl (201 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Installing collected packages: py-cpuinfo, urllib3, pyyaml, idna, charset-normalizer, certifi, requests, ultralytics-thop, seaborn, ultralytics\n",
      "Successfully installed certifi-2025.4.26 charset-normalizer-3.4.2 idna-3.10 py-cpuinfo-9.0.0 pyyaml-6.0.2 requests-2.32.3 seaborn-0.13.2 ultralytics-8.3.130 ultralytics-thop-2.0.14 urllib3-2.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the required package for YOLO11\n",
    "%pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9b9683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.130 üöÄ Python-3.10.17 torch-2.6.0 MPS (Apple M1)\n",
      "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolo11n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (5.4 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['coremltools>=8.0'] not found, attempting AutoUpdate...\n",
      "Collecting coremltools>=8.0\n",
      "  Downloading coremltools-8.3.0-cp310-none-macosx_11_0_arm64.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from coremltools>=8.0) (2.1.3)\n",
      "Requirement already satisfied: protobuf>=3.1.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from coremltools>=8.0) (5.29.4)\n",
      "Requirement already satisfied: sympy in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from coremltools>=8.0) (1.13.3)\n",
      "Requirement already satisfied: tqdm in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from coremltools>=8.0) (4.67.1)\n",
      "Requirement already satisfied: packaging in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from coremltools>=8.0) (25.0)\n",
      "Collecting attrs>=21.3.0 (from coremltools>=8.0)\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting cattrs (from coremltools>=8.0)\n",
      "  Downloading cattrs-24.1.3-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pyaml (from coremltools>=8.0)\n",
      "  Downloading pyaml-25.1.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.1.1 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from cattrs->coremltools>=8.0) (1.2.2)\n",
      "Requirement already satisfied: typing-extensions!=4.6.3,>=4.1.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from cattrs->coremltools>=8.0) (4.13.2)\n",
      "Requirement already satisfied: PyYAML in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from pyaml->coremltools>=8.0) (6.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from sympy->coremltools>=8.0) (1.3.0)\n",
      "Downloading coremltools-8.3.0-cp310-none-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading cattrs-24.1.3-py3-none-any.whl (66 kB)\n",
      "Downloading pyaml-25.1.0-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: pyaml, attrs, cattrs, coremltools\n",
      "Successfully installed attrs-25.3.0 cattrs-24.1.3 coremltools-8.3.0 pyaml-25.1.0\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ‚úÖ 6.4s, installed 1 package: ['coremltools>=8.0']\n",
      "WARNING ‚ö†Ô∏è \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:coremltools:scikit-learn version 1.6.1 is not supported. Minimum required version: 0.17. Maximum required version: 1.5.1. Disabling scikit-learn conversion API.\n",
      "WARNING:coremltools:TensorFlow version 2.19.0 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.12.0 is the most recent version that has been tested.\n",
      "WARNING:coremltools:Torch version 2.6.0 has not been tested with coremltools. You may run into unexpected errors. Torch 2.5.0 is the most recent version that has been tested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mCoreML:\u001b[0m starting export with coremltools 8.3.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:coremltools:Tuple detected at graph output. This will be flattened in the converted model.\n",
      "Converting PyTorch Frontend ==> MIL Ops: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 709/711 [00:00<00:00, 2769.08 ops/s]\n",
      "Running MIL frontend_pytorch pipeline: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 54.62 passes/s]\n",
      "Running MIL default pipeline: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 89/89 [00:02<00:00, 41.60 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:00<00:00, 65.00 passes/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mCoreML Pipeline:\u001b[0m starting pipeline with coremltools 8.3.0...\n",
      "\u001b[34m\u001b[1mCoreML Pipeline:\u001b[0m pipeline success\n",
      "\u001b[34m\u001b[1mCoreML:\u001b[0m export success ‚úÖ 29.0s, saved as 'yolo11n.mlpackage' (5.2 MB)\n",
      "\n",
      "Export complete (29.9s)\n",
      "Results saved to \u001b[1m/Users/kimwash/Projects/where2throw\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolo11n.mlpackage imgsz=640  \n",
      "Validate:        yolo val task=detect model=yolo11n.mlpackage imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yolo11n.mlpackage'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLO11 model\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Export the model to TFLite format\n",
    "model.export(format=\"coreml\", device='mps', nms=True)  # creates 'yolo11n_float32.tflite'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebcc0ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1bb13a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n",
      "Loading yolo11n_saved_model/yolo11n_float32.tflite for TensorFlow Lite inference...\n",
      "\n",
      "image 1/1 /Users/kimwash/Projects/where2throw/IMG_0383.jpeg: 640x640 1 laptop, 1 cell phone, 137.0ms\n",
      "Speed: 32.3ms preprocess, 137.0ms inference, 23.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "# Load the exported TFLite model\n",
    "tflite_model = YOLO(\"yolo11n_saved_model/yolo11n_float32.tflite\")\n",
    "\n",
    "# Run inference\n",
    "results = tflite_model(\"IMG_0383.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0332e8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process results list\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
    "    result.show()  # display to screen\n",
    "    result.save(filename=\"result.jpg\")  # save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac697cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (2.1.3)\n",
      "Requirement already satisfied: opencv-python in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (4.11.0.86)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tflite-runtime (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tflite-runtime\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy opencv-python tflite-runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b31c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 84, 8400)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# TFLite Î™®Îç∏ Î°úÎìú\n",
    "interpreter = tf.lite.Interpreter(model_path='./yolo11n_saved_model/yolo11n_float32.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# ÏûÖÎ†• Î∞è Ï∂úÎ†• ÌÖêÏÑú Ï†ïÎ≥¥ Í∞ÄÏ†∏Ïò§Í∏∞\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# ÏûÖÎ†• Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨\n",
    "image = Image.open('bus.jpg').convert('RGB')\n",
    "input_shape = input_details[0]['shape']\n",
    "image_resized = image.resize((input_shape[2], input_shape[1]))\n",
    "input_data = np.expand_dims(np.array(image_resized, dtype=np.float32), axis=0)\n",
    "\n",
    "# Ï∂îÎ°† Ïã§Ìñâ\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "interpreter.invoke()\n",
    "\n",
    "# Í≤∞Í≥º Í∞ÄÏ†∏Ïò§Í∏∞\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1811c24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def process_output(output_data, conf_threshold=0.5, iou_threshold=0.4, input_size=640):\n",
    "    # (1, 84, 8400) ‚Üí (8400, 84)\n",
    "    predictions = np.transpose(output_data[0])  # shape: (8400, 84)\n",
    "\n",
    "    boxes = predictions[:, 0:4]  # cx, cy, w, h\n",
    "    objectness = sigmoid(predictions[:, 4])\n",
    "    class_scores = sigmoid(predictions[:, 5:])  # shape: (8400, 80)\n",
    "\n",
    "    \n",
    "    scores = objectness[:, np.newaxis] * class_scores\n",
    "    class_ids = np.argmax(scores, axis=1)\n",
    "    confidences = np.max(scores, axis=1)\n",
    "    \n",
    "\n",
    "    # confidence ÌïÑÌÑ∞ÎßÅ\n",
    "    mask = confidences > conf_threshold\n",
    "    boxes = boxes[mask]\n",
    "    confidences = confidences[mask]\n",
    "    class_ids = class_ids[mask]\n",
    "\n",
    "    # Ï¢åÌëú Î≥ÄÌôò (cx, cy, w, h) ‚Üí (x1, y1, x2, y2)\n",
    "    boxes_xywh = boxes * input_size\n",
    "    boxes_xyxy = np.zeros_like(boxes_xywh)\n",
    "    boxes_xyxy[:, 0] = boxes_xywh[:, 0] - boxes_xywh[:, 2] / 2  # x1\n",
    "    boxes_xyxy[:, 1] = boxes_xywh[:, 1] - boxes_xywh[:, 3] / 2  # y1\n",
    "    boxes_xyxy[:, 2] = boxes_xywh[:, 0] + boxes_xywh[:, 2] / 2  # x2\n",
    "    boxes_xyxy[:, 3] = boxes_xywh[:, 1] + boxes_xywh[:, 3] / 2  # y2\n",
    "\n",
    "    # NMS ÏàòÌñâ\n",
    "    indices = cv2.dnn.NMSBoxes(\n",
    "        bboxes=boxes_xyxy.tolist(),\n",
    "        scores=confidences.tolist(),\n",
    "        score_threshold=conf_threshold,\n",
    "        nms_threshold=iou_threshold\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "    if len(indices) > 0:\n",
    "        for idx in indices.flatten():  # 1Ï∞®Ïõê Î∞∞Ïó¥Î°ú ÌôïÏã§Ìûà ÎßåÎì§Ïñ¥Ï§å\n",
    "            if confidences[idx] > 0.35:\n",
    "                results.append({\n",
    "                    \"box\": boxes_xyxy[idx],\n",
    "                    \"confidence\": float(confidences[idx]),\n",
    "                    \"class_id\": int(class_ids[idx])\n",
    "                })\n",
    "\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d05dd53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1   84 8400]\n"
     ]
    }
   ],
   "source": [
    "# Ï∂îÎ°† Í≤∞Í≥º ÏñªÍ∏∞\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "interpreter.invoke()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "interpreter.allocate_tensors()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(output_details[0]['shape'])  # Ïù¥Í≤å ÏßÑÏßú shapeÏûÑ\n",
    "\n",
    "# # ÌõÑÏ≤òÎ¶¨ ÏàòÌñâ\n",
    "# results = process_output(output_data, conf_threshold=0.1, iou_threshold=0.5, input_size=640)\n",
    "# # Í≤∞Í≥º Ï∂úÎ†•\n",
    "# for det in results:\n",
    "#     box = det['box']  # [x1, y1, x2, y2]\n",
    "#     cls = det['class_id']\n",
    "#     conf = det['confidence']\n",
    "#     print(f\"Class {cls} | Confidence {conf:.2f} | Box: {box}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d40fa514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def draw_detections(image, results, class_names=None):\n",
    "    \"\"\"\n",
    "    image: BGR Ïù¥ÎØ∏ÏßÄ (cv2.imreadÎ°ú Î∂àÎü¨Ïò® Í≤É)\n",
    "    results: process_output()ÏóêÏÑú ÎÇòÏò® Î¶¨Ïä§Ìä∏\n",
    "    class_names: ÏÑ†ÌÉùÏ†Å ÌÅ¥ÎûòÏä§ Ïù¥Î¶Ñ Î¶¨Ïä§Ìä∏ (COCO ÌÅ¥ÎûòÏä§ Îì±)\n",
    "    \"\"\"\n",
    "    for det in results:\n",
    "        x1, y1, x2, y2 = map(int, det['box'])\n",
    "        cls = det['class_id']\n",
    "        conf = det['confidence']\n",
    "\n",
    "        label = f\"{class_names[cls] if class_names else cls}: {conf:.2f}\"\n",
    "        \n",
    "        # Î∞îÏö¥Îî© Î∞ïÏä§\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "        # ÌÖçÏä§Ìä∏ Î∞∞Í≤Ω\n",
    "        (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "        cv2.rectangle(image, (x1, y1 - 20), (x1 + w, y1), (0, 255, 0), -1)\n",
    "        cv2.putText(image, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "    \n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b868d82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'box': [np.float32(828.0538), np.float32(856.79724), np.float32(882.94025), np.float32(856.8211)], 'confidence': 0.3896104693412781, 'class_id': 31}, {'box': [np.float32(1412.9553), np.float32(2293.2), np.float32(1750.9581), np.float32(2368.1982)], 'confidence': 0.36552929878234863, 'class_id': 66}, {'box': [np.float32(1397.1947), np.float32(1083.5284), np.float32(1878.2823), np.float32(1086.8567)], 'confidence': 0.36552926898002625, 'class_id': 66}, {'box': [np.float32(2171.0056), np.float32(1555.3418), np.float32(2620.5298), np.float32(1738.0841)], 'confidence': 0.36552688479423523, 'class_id': 66}, {'box': [np.float32(1821.9312), np.float32(2646.0), np.float32(1990.9468), np.float32(2646.307)], 'confidence': 0.3655221164226532, 'class_id': 66}, {'box': [np.float32(544.38806), np.float32(981.4581), np.float32(678.51306), np.float32(1033.1919)], 'confidence': 0.3655214011669159, 'class_id': 66}, {'box': [np.float32(193.11188), np.float32(1184.195), np.float32(298.2326), np.float32(1273.4026)], 'confidence': 0.36551833152770996, 'class_id': 66}, {'box': [np.float32(2.2271183), np.float32(3402.0), np.float32(363.04388), np.float32(3475.4744)], 'confidence': 0.36550748348236084, 'class_id': 66}, {'box': [np.float32(2858.2976), np.float32(1154.2782), np.float32(2994.2493), np.float32(1228.9247)], 'confidence': 0.3654358685016632, 'class_id': 66}, {'box': [np.float32(2536.191), np.float32(2542.193), np.float32(2756.0552), np.float32(2548.5354)], 'confidence': 0.3654349148273468, 'class_id': 66}, {'box': [np.float32(1083.017), np.float32(881.9981), np.float32(1233.54), np.float32(882.21265)], 'confidence': 0.3654323220252991, 'class_id': 66}, {'box': [np.float32(550.7117), np.float32(69.89179), np.float32(691.7884), np.float32(125.98069)], 'confidence': 0.3653907775878906, 'class_id': 66}, {'box': [np.float32(90.40239), np.float32(3401.9778), np.float32(515.4418), np.float32(3406.386)], 'confidence': 0.36536842584609985, 'class_id': 66}, {'box': [np.float32(818.6117), np.float32(1133.9995), np.float32(983.69354), np.float32(1234.7704)], 'confidence': 0.36534324288368225, 'class_id': 66}, {'box': [np.float32(298.0358), np.float32(931.1911), np.float32(504.33255), np.float32(933.7297)], 'confidence': 0.3652120530605316, 'class_id': 66}, {'box': [np.float32(551.0466), np.float32(2661.0957), np.float32(929.74097), np.float32(2829.458)], 'confidence': 0.36517083644866943, 'class_id': 66}, {'box': [np.float32(2468.4482), np.float32(3418.2935), np.float32(2980.8345), np.float32(3465.7756)], 'confidence': 0.36508792638778687, 'class_id': 66}, {'box': [np.float32(708.31757), np.float32(3136.6838), np.float32(1226.2822), np.float32(3203.6882)], 'confidence': 0.3647775650024414, 'class_id': 66}, {'box': [np.float32(-294.1627), np.float32(3401.9917), np.float32(595.0403), np.float32(3453.2122)], 'confidence': 0.36475247144699097, 'class_id': 66}, {'box': [np.float32(649.2672), np.float32(68.37738), np.float32(828.558), np.float32(166.52356)], 'confidence': 0.3647039532661438, 'class_id': 66}, {'box': [np.float32(1074.6465), np.float32(2758.8164), np.float32(1501.9414), np.float32(2912.8765)], 'confidence': 0.36448413133621216, 'class_id': 66}, {'box': [np.float32(444.5761), np.float32(720.9756), np.float32(821.29156), np.float32(902.74603)], 'confidence': 0.3642353415489197, 'class_id': 66}, {'box': [np.float32(785.2983), np.float32(1889.9802), np.float32(1041.6885), np.float32(1940.1738)], 'confidence': 0.36410272121429443, 'class_id': 66}, {'box': [np.float32(100.55805), np.float32(2814.0212), np.float32(666.2783), np.float32(3076.4807)], 'confidence': 0.36406001448631287, 'class_id': 66}, {'box': [np.float32(1687.8362), np.float32(932.399), np.float32(1850.1715), np.float32(932.46454)], 'confidence': 0.3632526993751526, 'class_id': 64}, {'box': [np.float32(2321.1274), np.float32(982.796), np.float32(2446.336), np.float32(983.0701)], 'confidence': 0.36307820677757263, 'class_id': 66}, {'box': [np.float32(577.3217), np.float32(2132.7043), np.float32(940.39764), np.float32(2217.541)], 'confidence': 0.363073468208313, 'class_id': 66}, {'box': [np.float32(1503.2572), np.float32(579.5515), np.float32(2013.2391), np.float32(680.39996)], 'confidence': 0.36275479197502136, 'class_id': 66}, {'box': [np.float32(447.91602), np.float32(46.21708), np.float32(575.36096), np.float32(113.60363)], 'confidence': 0.3611515760421753, 'class_id': 66}, {'box': [np.float32(2683.752), np.float32(1744.3887), np.float32(3091.0334), np.float32(1968.1533)], 'confidence': 0.3610284924507141, 'class_id': 66}, {'box': [np.float32(-38.827663), np.float32(980.4239), np.float32(389.77832), np.float32(1118.4048)], 'confidence': 0.3596715033054352, 'class_id': 66}, {'box': [np.float32(2662.0908), np.float32(75.57674), np.float32(2883.5227), np.float32(156.45676)], 'confidence': 0.35505470633506775, 'class_id': 66}, {'box': [np.float32(435.201), np.float32(3400.4224), np.float32(946.4257), np.float32(3402.292)], 'confidence': 0.35355567932128906, 'class_id': 66}, {'box': [np.float32(2296.8408), np.float32(2083.032), np.float32(2777.6973), np.float32(2142.0022)], 'confidence': 0.3524645268917084, 'class_id': 66}]\n"
     ]
    }
   ],
   "source": [
    "original_image = Image.open(\"test.jpg\").convert(\"RGB\")\n",
    "original_size = original_image.size  # (width, height)\n",
    "\n",
    "image_resized = original_image.resize((640, 640))\n",
    "input_data = np.expand_dims(np.array(image_resized, dtype=np.float32), axis=0)\n",
    "def resize_boxes_to_original(results, original_size, input_size=640):\n",
    "    \"\"\"\n",
    "    input_size: Î™®Îç∏ ÏûÖÎ†• ÌÅ¨Í∏∞ (Í∏∞Î≥∏ 640)\n",
    "    original_size: (width, height)\n",
    "    \"\"\"\n",
    "    ow, oh = original_size\n",
    "    scale_w = ow / input_size\n",
    "    scale_h = oh / input_size\n",
    "\n",
    "    for det in results:\n",
    "        x1, y1, x2, y2 = det['box']\n",
    "        det['box'] = [\n",
    "            x1 * scale_w,\n",
    "            y1 * scale_h,\n",
    "            x2 * scale_w,\n",
    "            y2 * scale_h\n",
    "        ]\n",
    "    return results\n",
    "\n",
    "results = process_output(output_data, conf_threshold=0.1, iou_threshold=0.5, input_size=640)\n",
    "results = resize_boxes_to_original(results, original_size=(original_image.width, original_image.height))\n",
    "print(results)\n",
    "# Ïù¥Ï†ú ÏõêÎ≥∏ Ïù¥ÎØ∏ÏßÄ ÏúÑÏóê Í∑∏Î¶¥ Ïàò ÏûàÏùå\n",
    "image_bgr = cv2.cvtColor(np.array(original_image), cv2.COLOR_RGB2BGR)\n",
    "output_image = draw_detections(image_bgr.copy(), results)\n",
    "# Í≤∞Í≥º Î≥¥Í∏∞\n",
    "cv2.imshow(\"Detections\", output_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cf9265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%yolo` not found.\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "waste-classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
