#import <VisionCamera/FrameProcessorPlugin.h>
#import <VisionCamera/FrameProcessorPluginRegistry.h>
#import <VisionCamera/VisionCameraProxyHolder.h>
#import <VisionCamera/Frame.h>
#import <Foundation/Foundation.h>
#import <UIKit/UIKit.h>
#import <CoreMedia/CoreMedia.h>
#import <onnxruntime_cxx_api.h>

@interface TrashSorterPlugin : FrameProcessorPlugin {
    Ort::Env *ortEnv;
    Ort::Session *ortSession;
    std::vector<const char*> inputNames;
    std::vector<const char*> outputNames;
}
@end

@implementation TrashSorterPlugin

- (NSString *)debugLogPath {
  NSArray* paths = NSSearchPathForDirectoriesInDomains(NSDocumentDirectory, NSUserDomainMask, YES);
  NSString* documentsDirectory = [paths objectAtIndex:0];
  return [documentsDirectory stringByAppendingPathComponent:@"onnx_debug.txt"];
}

- (void)appendDebugLog:(NSString *)log {
  NSString *logPath = [self debugLogPath];
  NSFileHandle *fileHandle = [NSFileHandle fileHandleForWritingAtPath:logPath];
  if (!fileHandle) {
    [log writeToFile:logPath atomically:YES encoding:NSUTF8StringEncoding error:nil];
  } else {
    [fileHandle seekToEndOfFile];
    NSString *line = [NSString stringWithFormat:@"%@\n", log];
    [fileHandle writeData:[line dataUsingEncoding:NSUTF8StringEncoding]];
    [fileHandle closeFile];
  }
}

#pragma mark - Public Initializers

/// VisionCamera FrameProcessorÏö© Í∏∞Î≥∏ Ïù¥ÎãàÏÖúÎùºÏù¥Ï†Ä
- (instancetype)initWithProxy:(VisionCameraProxyHolder*)proxy
                  withOptions:(NSDictionary*)options {
  self = [super initWithProxy:proxy withOptions:options];
  if (self) {
    [self setupONNXSession];
  }
  return self;
}

/// ‚úÖ ÌÖåÏä§Ìä∏ Ï†ÑÏö© Ïù¥ÎãàÏÖúÎùºÏù¥Ï†Ä (VisionCamera ÌïÑÏöî ÏóÜÏùå)
- (instancetype)initForTesting {
  VisionCameraProxyHolder* dummyProxy = [[VisionCameraProxyHolder alloc] init]; // Mock Proxy ÏÉùÏÑ±
  self = [super initWithProxy:dummyProxy withOptions:nil];
  if (self) {
    [self setupONNXSession];
  }
  return self;
}


#pragma mark - Private Setup

/// ONNX Î™®Îç∏ Î°úÎî© Î∞è ÏÑ∏ÏÖò Ï¥àÍ∏∞Ìôî
- (void)setupONNXSession {
  try {
    ortEnv = new Ort::Env(ORT_LOGGING_LEVEL_WARNING, "TrashSorterTest");

    Ort::SessionOptions sessionOptions;
    sessionOptions.SetIntraOpNumThreads(1);

    NSString *modelPath = [[NSBundle mainBundle] pathForResource:@"waste_classifier" ofType:@"ort"];
    if (!modelPath) {
      [self appendDebugLog:@"‚ùå Model not found!"];
      return;
    }

    ortSession = new Ort::Session(*ortEnv, [modelPath UTF8String], sessionOptions);

    Ort::AllocatorWithDefaultOptions allocator;

    auto inputNamePtr = ortSession->GetInputNameAllocated(0, allocator);
    auto outputNamePtr = ortSession->GetOutputNameAllocated(0, allocator);

    inputNames = {strdup(inputNamePtr.get())};
    outputNames = {strdup(outputNamePtr.get())};

    [self appendDebugLog:@"‚úÖ TrashSorterPlugin ONNX session initialized!"];
  }
  catch (const Ort::Exception& e) {
    NSLog(@"‚ùå ONNX Error: %s", e.what());
    [self appendDebugLog:[NSString stringWithFormat:@"‚úÖ ONNX Error: %s", e.what()]];

    ortSession = nullptr;
    ortEnv = nullptr;
  }
}
#pragma mark - SampleBuffer -> PixelBuffer Î≥ÄÌôò

- (CVPixelBufferRef _Nullable)pixelBufferFromSampleBuffer:(CMSampleBufferRef)sampleBuffer {
  if (sampleBuffer == nil) {
    NSLog(@"‚ùå sampleBuffer is nil.");
    return nil;
  }

  CVPixelBufferRef pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer);
  if (pixelBuffer == nil) {
    NSLog(@"‚ùå Failed to get pixelBuffer from sampleBuffer.");
    return nil;
  }

  // retain ÏóÜÏù¥ Î∞îÎ°ú Î∞òÌôòÌï¥ÎèÑ OK (CMSampleBuffer ÎÇ¥Î∂Ä Í¥ÄÎ¶¨)
  return pixelBuffer;
}
#pragma mark - PixelBuffer -> UIImage Î≥ÄÌôò

- (UIImage* _Nullable)uiImageFromPixelBuffer:(CVPixelBufferRef)pixelBuffer {
  if (pixelBuffer == nil) {
    NSLog(@"‚ùå pixelBuffer is nil.");
    return nil;
  }

  CVPixelBufferLockBaseAddress(pixelBuffer, kCVPixelBufferLock_ReadOnly);

  size_t width = CVPixelBufferGetWidth(pixelBuffer);
  size_t height = CVPixelBufferGetHeight(pixelBuffer);
  uint8_t* baseAddress = (uint8_t*)CVPixelBufferGetBaseAddress(pixelBuffer);
  size_t bytesPerRow = CVPixelBufferGetBytesPerRow(pixelBuffer);

  CGColorSpaceRef colorSpace = CGColorSpaceCreateDeviceRGB();
  CGContextRef context = CGBitmapContextCreate(
    baseAddress,
    width,
    height,
    8,
    bytesPerRow,
    colorSpace,
    kCGImageAlphaPremultipliedFirst | kCGBitmapByteOrder32Little
  );

  if (context == nil) {
    NSLog(@"‚ùå Failed to create CGContext.");
    CVPixelBufferUnlockBaseAddress(pixelBuffer, kCVPixelBufferLock_ReadOnly);
    CGColorSpaceRelease(colorSpace);
    return nil;
  }

  CGImageRef quartzImage = CGBitmapContextCreateImage(context);
  UIImage* image = [UIImage imageWithCGImage:quartzImage];

  // Clean up
  CGImageRelease(quartzImage);
  CGContextRelease(context);
  CGColorSpaceRelease(colorSpace);
  CVPixelBufferUnlockBaseAddress(pixelBuffer, kCVPixelBufferLock_ReadOnly);

  return image;
}

- (std::vector<float>)floatBufferFromUIImage:(UIImage *)image {
    // Ïù¥ÎØ∏ÏßÄ Î¶¨ÏÇ¨Ïù¥Ïßï (224x224)
    CGSize size = CGSizeMake(224, 224);
    UIGraphicsBeginImageContextWithOptions(size, YES, 1.0);
    [image drawInRect:CGRectMake(0, 0, size.width, size.height)];
    UIImage *resizedImage = UIGraphicsGetImageFromCurrentImageContext();
    UIGraphicsEndImageContext();
    
    // CGImage ÌöçÎìù
    CGImageRef cgImage = resizedImage.CGImage;
    
    // RGB ÌîΩÏÖÄ Îç∞Ïù¥ÌÑ∞ Ï∂îÏ∂ú
    size_t width = CGImageGetWidth(cgImage);
    size_t height = CGImageGetHeight(cgImage);
    size_t bitsPerComponent = 8;
    size_t bytesPerRow = width * 4;
    
    uint8_t *rawData = (uint8_t *)calloc(height * width * 4, sizeof(uint8_t));
    CGColorSpaceRef colorSpace = CGColorSpaceCreateDeviceRGB();
    CGContextRef context = CGBitmapContextCreate(rawData, width, height, bitsPerComponent, bytesPerRow, colorSpace, kCGImageAlphaPremultipliedLast | kCGBitmapByteOrder32Big);
    CGContextDrawImage(context, CGRectMake(0, 0, width, height), cgImage);
    
    // ÌîΩÏÖÄ Îç∞Ïù¥ÌÑ∞Î•º float Î∞∞Ïó¥Î°ú Î≥ÄÌôò (RGB Ï±ÑÎÑê)
    std::vector<float> floatArray(3 * width * height);
    
    // ÌîΩÏÖÄ Í∞í Ï†ïÍ∑úÌôî (0-255 -> 0-1)
    for (int y = 0; y < height; y++) {
        for (int x = 0; x < width; x++) {
            int offset = (y * width + x) * 4;
            // R, G, B Ï±ÑÎÑê (0-1 Î≤îÏúÑÎ°ú Ï†ïÍ∑úÌôî)
            floatArray[y * width + x] = rawData[offset] / 255.0f;                   // R
            floatArray[width * height + y * width + x] = rawData[offset + 1] / 255.0f;  // G
            floatArray[2 * width * height + y * width + x] = rawData[offset + 2] / 255.0f; // B
        }
    }
    
    // Î©îÎ™®Î¶¨ Ìï¥Ï†ú
    free(rawData);
    CGContextRelease(context);
    CGColorSpaceRelease(colorSpace);
    
    return floatArray;
}


#pragma mark - Í≥µÌÜµ Ï∂îÎ°† Ìï®Ïàò

- (NSNumber* _Nullable)runInferenceWithUIImage:(UIImage*)image {
  try {
    if (!ortSession) {
      NSLog(@"Session is not initilized!");
      [self appendDebugLog:@"‚ùå ONNX Session isn't initialized!"];
      return nil;
    }

      // UIImageÏóêÏÑú float Î≤°ÌÑ∞ ÏÉùÏÑ±
      std::vector<float> inputTensorValues = [self floatBufferFromUIImage:image];
    [self appendDebugLog:[NSString stringWithFormat:@"‚úÖ inputTesorValues size: %zu", inputTensorValues.size()]];

      
      // ÏûÖÎ†• ÌÖêÏÑú ÌÅ¨Í∏∞ Î∞è Ï†ïÎ≥¥ ÏÑ§Ï†ï
      std::vector<int64_t> inputDims = {1, 3, 224, 224};  // Î∞∞Ïπò, Ï±ÑÎÑê, ÎÜíÏù¥, ÎÑàÎπÑ
      
      // Î©îÎ™®Î¶¨ Ï†ïÎ≥¥
      Ort::MemoryInfo memoryInfo = Ort::MemoryInfo::CreateCpu(OrtArenaAllocator, OrtMemTypeDefault);
    [self appendDebugLog:[NSString stringWithFormat:@"‚úÖ memory created: %s", memoryInfo.GetConst().GetAllocatorName().c_str()]];
      // ÏûÖÎ†• ÌÖêÏÑú ÏÉùÏÑ±
      Ort::Value inputTensor = Ort::Value::CreateTensor<float>(
          memoryInfo,
          inputTensorValues.data(),
          inputTensorValues.size(),
          inputDims.data(),
          inputDims.size()
      );
    [self appendDebugLog:[NSString stringWithFormat:@"‚úÖ inputTensor created. isTensor: %b", inputTensor.GetConst().IsTensor()]];
    [self appendDebugLog:@"üöÄ Running Inference... "];

      
      // Î™®Îç∏ Ïã§Ìñâ
      std::vector<Ort::Value> outputTensors = ortSession->Run(
          Ort::RunOptions{nullptr},
          inputNames.data(),
          &inputTensor,
          1,
          outputNames.data(),
          1
      );
    [self appendDebugLog:@"‚úÖ Inference done!"];

      
      // Í≤∞Í≥º Ï≤òÎ¶¨
      float* outputData = outputTensors[0].GetTensorMutableData<float>();
    [self appendDebugLog:[NSString stringWithFormat:@"‚úÖ outputData size: %lu", sizeof outputData]];

      
      // ÌÖêÏÑú Ï†ïÎ≥¥ Í∞ÄÏ†∏Ïò§Í∏∞
      Ort::TypeInfo typeInfo = outputTensors[0].GetTypeInfo();
    [self appendDebugLog:@"‚úÖ typeInfo done!"];


      const Ort::ConstTensorTypeAndShapeInfo tensorInfo = typeInfo.GetTensorTypeAndShapeInfo();
    [self appendDebugLog:@"‚úÖ tensorInfo done!"];

      std::vector<int64_t> outputDims = tensorInfo.GetShape();
    [self appendDebugLog:[NSString stringWithFormat:@"‚úÖ GetShape done! size: %lu", outputDims.size()]];

      size_t outputSize = 1;
      for (size_t i = 0; i < outputDims.size(); i++) {
          if (outputDims[i] > 0) {
              outputSize *= outputDims[i];
          }
      }
    
    [self appendDebugLog:[NSString stringWithFormat:@"‚úÖ outputSize: %lu", outputSize]];

      
      // ÏµúÎåÄÍ∞íÍ≥º Ìï¥Îãπ Ïù∏Îç±Ïä§ Ï∞æÍ∏∞
      int maxIndex = -1;
      float maxValue = -std::numeric_limits<float>::max();
      
      for (size_t i = 0; i < outputSize; i++) {
          if (outputData[i] > maxValue) {
              maxValue = outputData[i];
              maxIndex = static_cast<int>(i);
          }
      }
      
      // Ïù∏Îç±Ïä§ Î∞òÌôò
    [self appendDebugLog:[NSString stringWithFormat:@"‚úÖ Prediction: %d", maxIndex]];

      return @(maxIndex);
  }
  catch (const Ort::Exception& e) {
      NSLog(@"ONNX Runtime Error during inference: %s", e.what());
      return nil;
  }
  catch (const std::exception& e) {
      NSLog(@"Standard exception during inference: %s", e.what());
      return nil;
  }
  catch (...) {
      NSLog(@"Unknown error during inference");
      return nil;
  }
  
}

#pragma mark - VisionCamera FrameÏóêÏÑú Ìò∏Ï∂ú

- (NSNumber* _Nullable)callback:(Frame* _Nonnull)frame withArguments:(NSDictionary* _Nullable)arguments {
  CVPixelBufferRef pixelBuffer = CMSampleBufferGetImageBuffer(frame.buffer);
  [self appendDebugLog:@"‚úÖ PixelBuffer taken from SampleBuffer OK"];
  UIImage* image = [self uiImageFromPixelBuffer:pixelBuffer];
  [self appendDebugLog:@"‚úÖ UIImage from PixelBuffer OK"];
  if (!pixelBuffer) {
    [self appendDebugLog:@"‚ùå pixelBuffer is nil."];
    return nil;
  }
  [self appendDebugLog:@"üöÄ Running inference with UIImage! "];
  return [self runInferenceWithUIImage:image];
}





- (void)dealloc {
  // Î¶¨ÏÜåÏä§ Ï†ïÎ¶¨
    for (auto ptr : inputNames) if (ptr) free((void*)ptr);
    for (auto ptr : outputNames) if (ptr) free((void*)ptr);

    
    if (ortSession) {
        delete ortSession;
        ortSession = nullptr;
    }
    if (ortEnv) {
        delete ortEnv;
        ortEnv = nullptr;
    }
    
}

VISION_EXPORT_FRAME_PROCESSOR(TrashSorterPlugin, runWasteClassifier)

@end
