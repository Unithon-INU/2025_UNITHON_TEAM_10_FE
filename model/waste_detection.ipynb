{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7637e487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.130-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from ultralytics) (2.2.5)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from ultralytics) (3.10.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from ultralytics) (11.1.0)\n",
      "Collecting pyyaml>=5.3.1 (from ultralytics)\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting requests>=2.23.0 (from ultralytics)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from ultralytics) (1.15.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from ultralytics) (2.6.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from ultralytics) (0.21.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from ultralytics) (7.0.0)\n",
      "Collecting py-cpuinfo (from ultralytics)\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from ultralytics) (2.2.3)\n",
      "Collecting seaborn>=0.11.0 (from ultralytics)\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.23.0->ultralytics)\n",
      "  Downloading charset_normalizer-3.4.2-cp310-cp310-macosx_10_9_universal2.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.23.0->ultralytics)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.23.0->ultralytics)\n",
      "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.23.0->ultralytics)\n",
      "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: filelock in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
      "Requirement already satisfied: sympy!=1.13.2,>=1.13.1 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from sympy!=1.13.2,>=1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Downloading ultralytics-8.3.130-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.2-cp310-cp310-macosx_11_0_arm64.whl (171 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
      "Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "Downloading charset_normalizer-3.4.2-cp310-cp310-macosx_10_9_universal2.whl (201 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Installing collected packages: py-cpuinfo, urllib3, pyyaml, idna, charset-normalizer, certifi, requests, ultralytics-thop, seaborn, ultralytics\n",
      "Successfully installed certifi-2025.4.26 charset-normalizer-3.4.2 idna-3.10 py-cpuinfo-9.0.0 pyyaml-6.0.2 requests-2.32.3 seaborn-0.13.2 ultralytics-8.3.130 ultralytics-thop-2.0.14 urllib3-2.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the required package for YOLO11\n",
    "%pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9b9683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.130 🚀 Python-3.10.17 torch-2.6.0 MPS (Apple M1)\n",
      "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolo11n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (5.4 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['coremltools>=8.0'] not found, attempting AutoUpdate...\n",
      "Collecting coremltools>=8.0\n",
      "  Downloading coremltools-8.3.0-cp310-none-macosx_11_0_arm64.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from coremltools>=8.0) (2.1.3)\n",
      "Requirement already satisfied: protobuf>=3.1.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from coremltools>=8.0) (5.29.4)\n",
      "Requirement already satisfied: sympy in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from coremltools>=8.0) (1.13.3)\n",
      "Requirement already satisfied: tqdm in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from coremltools>=8.0) (4.67.1)\n",
      "Requirement already satisfied: packaging in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from coremltools>=8.0) (25.0)\n",
      "Collecting attrs>=21.3.0 (from coremltools>=8.0)\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting cattrs (from coremltools>=8.0)\n",
      "  Downloading cattrs-24.1.3-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pyaml (from coremltools>=8.0)\n",
      "  Downloading pyaml-25.1.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.1.1 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from cattrs->coremltools>=8.0) (1.2.2)\n",
      "Requirement already satisfied: typing-extensions!=4.6.3,>=4.1.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from cattrs->coremltools>=8.0) (4.13.2)\n",
      "Requirement already satisfied: PyYAML in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from pyaml->coremltools>=8.0) (6.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from sympy->coremltools>=8.0) (1.3.0)\n",
      "Downloading coremltools-8.3.0-cp310-none-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading cattrs-24.1.3-py3-none-any.whl (66 kB)\n",
      "Downloading pyaml-25.1.0-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: pyaml, attrs, cattrs, coremltools\n",
      "Successfully installed attrs-25.3.0 cattrs-24.1.3 coremltools-8.3.0 pyaml-25.1.0\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 6.4s, installed 1 package: ['coremltools>=8.0']\n",
      "WARNING ⚠️ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:coremltools:scikit-learn version 1.6.1 is not supported. Minimum required version: 0.17. Maximum required version: 1.5.1. Disabling scikit-learn conversion API.\n",
      "WARNING:coremltools:TensorFlow version 2.19.0 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.12.0 is the most recent version that has been tested.\n",
      "WARNING:coremltools:Torch version 2.6.0 has not been tested with coremltools. You may run into unexpected errors. Torch 2.5.0 is the most recent version that has been tested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mCoreML:\u001b[0m starting export with coremltools 8.3.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:coremltools:Tuple detected at graph output. This will be flattened in the converted model.\n",
      "Converting PyTorch Frontend ==> MIL Ops: 100%|█████████▉| 709/711 [00:00<00:00, 2769.08 ops/s]\n",
      "Running MIL frontend_pytorch pipeline: 100%|██████████| 5/5 [00:00<00:00, 54.62 passes/s]\n",
      "Running MIL default pipeline: 100%|██████████| 89/89 [00:02<00:00, 41.60 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|██████████| 12/12 [00:00<00:00, 65.00 passes/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mCoreML Pipeline:\u001b[0m starting pipeline with coremltools 8.3.0...\n",
      "\u001b[34m\u001b[1mCoreML Pipeline:\u001b[0m pipeline success\n",
      "\u001b[34m\u001b[1mCoreML:\u001b[0m export success ✅ 29.0s, saved as 'yolo11n.mlpackage' (5.2 MB)\n",
      "\n",
      "Export complete (29.9s)\n",
      "Results saved to \u001b[1m/Users/kimwash/Projects/where2throw\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolo11n.mlpackage imgsz=640  \n",
      "Validate:        yolo val task=detect model=yolo11n.mlpackage imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yolo11n.mlpackage'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLO11 model\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Export the model to TFLite format\n",
    "model.export(format=\"coreml\", device='mps', nms=True)  # creates 'yolo11n CoreML Model'\n",
    "model.export(format=\"tflite\", device='mps', nms=True)  # creates 'yolo11n_float32.tflite'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebcc0ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1bb13a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n",
      "Loading yolo11n_saved_model/yolo11n_float32.tflite for TensorFlow Lite inference...\n",
      "\n",
      "image 1/1 /Users/kimwash/Projects/where2throw/IMG_0383.jpeg: 640x640 1 laptop, 1 cell phone, 137.0ms\n",
      "Speed: 32.3ms preprocess, 137.0ms inference, 23.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "# Load the exported TFLite model\n",
    "tflite_model = YOLO(\"yolo11n_saved_model/yolo11n_float32.tflite\")\n",
    "\n",
    "# Run inference\n",
    "results = tflite_model(\"IMG_0383.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0332e8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process results list\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
    "    result.show()  # display to screen\n",
    "    result.save(filename=\"result.jpg\")  # save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac697cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (2.1.3)\n",
      "Requirement already satisfied: opencv-python in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (4.11.0.86)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tflite-runtime (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tflite-runtime\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy opencv-python tflite-runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b31c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 84, 8400)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# TFLite 모델 로드\n",
    "interpreter = tf.lite.Interpreter(model_path='./yolo11n_saved_model/yolo11n_float32.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# 입력 및 출력 텐서 정보 가져오기\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# 입력 이미지 전처리\n",
    "image = Image.open('bus.jpg').convert('RGB')\n",
    "input_shape = input_details[0]['shape']\n",
    "image_resized = image.resize((input_shape[2], input_shape[1]))\n",
    "input_data = np.expand_dims(np.array(image_resized, dtype=np.float32), axis=0)\n",
    "\n",
    "# 추론 실행\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "interpreter.invoke()\n",
    "\n",
    "# 결과 가져오기\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1811c24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def process_output(output_data, conf_threshold=0.5, iou_threshold=0.4, input_size=640):\n",
    "    # (1, 84, 8400) → (8400, 84)\n",
    "    predictions = np.transpose(output_data[0])  # shape: (8400, 84)\n",
    "\n",
    "    boxes = predictions[:, 0:4]  # cx, cy, w, h\n",
    "    objectness = sigmoid(predictions[:, 4])\n",
    "    class_scores = sigmoid(predictions[:, 5:])  # shape: (8400, 80)\n",
    "\n",
    "    \n",
    "    scores = objectness[:, np.newaxis] * class_scores\n",
    "    class_ids = np.argmax(scores, axis=1)\n",
    "    confidences = np.max(scores, axis=1)\n",
    "    \n",
    "\n",
    "    # confidence 필터링\n",
    "    mask = confidences > conf_threshold\n",
    "    boxes = boxes[mask]\n",
    "    confidences = confidences[mask]\n",
    "    class_ids = class_ids[mask]\n",
    "\n",
    "    # 좌표 변환 (cx, cy, w, h) → (x1, y1, x2, y2)\n",
    "    boxes_xywh = boxes * input_size\n",
    "    boxes_xyxy = np.zeros_like(boxes_xywh)\n",
    "    boxes_xyxy[:, 0] = boxes_xywh[:, 0] - boxes_xywh[:, 2] / 2  # x1\n",
    "    boxes_xyxy[:, 1] = boxes_xywh[:, 1] - boxes_xywh[:, 3] / 2  # y1\n",
    "    boxes_xyxy[:, 2] = boxes_xywh[:, 0] + boxes_xywh[:, 2] / 2  # x2\n",
    "    boxes_xyxy[:, 3] = boxes_xywh[:, 1] + boxes_xywh[:, 3] / 2  # y2\n",
    "\n",
    "    # NMS 수행\n",
    "    indices = cv2.dnn.NMSBoxes(\n",
    "        bboxes=boxes_xyxy.tolist(),\n",
    "        scores=confidences.tolist(),\n",
    "        score_threshold=conf_threshold,\n",
    "        nms_threshold=iou_threshold\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "    if len(indices) > 0:\n",
    "        for idx in indices.flatten():  # 1차원 배열로 확실히 만들어줌\n",
    "            if confidences[idx] > 0.35:\n",
    "                results.append({\n",
    "                    \"box\": boxes_xyxy[idx],\n",
    "                    \"confidence\": float(confidences[idx]),\n",
    "                    \"class_id\": int(class_ids[idx])\n",
    "                })\n",
    "\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d05dd53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1   84 8400]\n"
     ]
    }
   ],
   "source": [
    "# 추론 결과 얻기\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "interpreter.invoke()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "interpreter.allocate_tensors()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(output_details[0]['shape'])  # 이게 진짜 shape임\n",
    "\n",
    "# # 후처리 수행\n",
    "# results = process_output(output_data, conf_threshold=0.1, iou_threshold=0.5, input_size=640)\n",
    "# # 결과 출력\n",
    "# for det in results:\n",
    "#     box = det['box']  # [x1, y1, x2, y2]\n",
    "#     cls = det['class_id']\n",
    "#     conf = det['confidence']\n",
    "#     print(f\"Class {cls} | Confidence {conf:.2f} | Box: {box}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d40fa514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def draw_detections(image, results, class_names=None):\n",
    "    \"\"\"\n",
    "    image: BGR 이미지 (cv2.imread로 불러온 것)\n",
    "    results: process_output()에서 나온 리스트\n",
    "    class_names: 선택적 클래스 이름 리스트 (COCO 클래스 등)\n",
    "    \"\"\"\n",
    "    for det in results:\n",
    "        x1, y1, x2, y2 = map(int, det['box'])\n",
    "        cls = det['class_id']\n",
    "        conf = det['confidence']\n",
    "\n",
    "        label = f\"{class_names[cls] if class_names else cls}: {conf:.2f}\"\n",
    "        \n",
    "        # 바운딩 박스\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "        # 텍스트 배경\n",
    "        (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "        cv2.rectangle(image, (x1, y1 - 20), (x1 + w, y1), (0, 255, 0), -1)\n",
    "        cv2.putText(image, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "    \n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b868d82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'box': [np.float32(828.0538), np.float32(856.79724), np.float32(882.94025), np.float32(856.8211)], 'confidence': 0.3896104693412781, 'class_id': 31}, {'box': [np.float32(1412.9553), np.float32(2293.2), np.float32(1750.9581), np.float32(2368.1982)], 'confidence': 0.36552929878234863, 'class_id': 66}, {'box': [np.float32(1397.1947), np.float32(1083.5284), np.float32(1878.2823), np.float32(1086.8567)], 'confidence': 0.36552926898002625, 'class_id': 66}, {'box': [np.float32(2171.0056), np.float32(1555.3418), np.float32(2620.5298), np.float32(1738.0841)], 'confidence': 0.36552688479423523, 'class_id': 66}, {'box': [np.float32(1821.9312), np.float32(2646.0), np.float32(1990.9468), np.float32(2646.307)], 'confidence': 0.3655221164226532, 'class_id': 66}, {'box': [np.float32(544.38806), np.float32(981.4581), np.float32(678.51306), np.float32(1033.1919)], 'confidence': 0.3655214011669159, 'class_id': 66}, {'box': [np.float32(193.11188), np.float32(1184.195), np.float32(298.2326), np.float32(1273.4026)], 'confidence': 0.36551833152770996, 'class_id': 66}, {'box': [np.float32(2.2271183), np.float32(3402.0), np.float32(363.04388), np.float32(3475.4744)], 'confidence': 0.36550748348236084, 'class_id': 66}, {'box': [np.float32(2858.2976), np.float32(1154.2782), np.float32(2994.2493), np.float32(1228.9247)], 'confidence': 0.3654358685016632, 'class_id': 66}, {'box': [np.float32(2536.191), np.float32(2542.193), np.float32(2756.0552), np.float32(2548.5354)], 'confidence': 0.3654349148273468, 'class_id': 66}, {'box': [np.float32(1083.017), np.float32(881.9981), np.float32(1233.54), np.float32(882.21265)], 'confidence': 0.3654323220252991, 'class_id': 66}, {'box': [np.float32(550.7117), np.float32(69.89179), np.float32(691.7884), np.float32(125.98069)], 'confidence': 0.3653907775878906, 'class_id': 66}, {'box': [np.float32(90.40239), np.float32(3401.9778), np.float32(515.4418), np.float32(3406.386)], 'confidence': 0.36536842584609985, 'class_id': 66}, {'box': [np.float32(818.6117), np.float32(1133.9995), np.float32(983.69354), np.float32(1234.7704)], 'confidence': 0.36534324288368225, 'class_id': 66}, {'box': [np.float32(298.0358), np.float32(931.1911), np.float32(504.33255), np.float32(933.7297)], 'confidence': 0.3652120530605316, 'class_id': 66}, {'box': [np.float32(551.0466), np.float32(2661.0957), np.float32(929.74097), np.float32(2829.458)], 'confidence': 0.36517083644866943, 'class_id': 66}, {'box': [np.float32(2468.4482), np.float32(3418.2935), np.float32(2980.8345), np.float32(3465.7756)], 'confidence': 0.36508792638778687, 'class_id': 66}, {'box': [np.float32(708.31757), np.float32(3136.6838), np.float32(1226.2822), np.float32(3203.6882)], 'confidence': 0.3647775650024414, 'class_id': 66}, {'box': [np.float32(-294.1627), np.float32(3401.9917), np.float32(595.0403), np.float32(3453.2122)], 'confidence': 0.36475247144699097, 'class_id': 66}, {'box': [np.float32(649.2672), np.float32(68.37738), np.float32(828.558), np.float32(166.52356)], 'confidence': 0.3647039532661438, 'class_id': 66}, {'box': [np.float32(1074.6465), np.float32(2758.8164), np.float32(1501.9414), np.float32(2912.8765)], 'confidence': 0.36448413133621216, 'class_id': 66}, {'box': [np.float32(444.5761), np.float32(720.9756), np.float32(821.29156), np.float32(902.74603)], 'confidence': 0.3642353415489197, 'class_id': 66}, {'box': [np.float32(785.2983), np.float32(1889.9802), np.float32(1041.6885), np.float32(1940.1738)], 'confidence': 0.36410272121429443, 'class_id': 66}, {'box': [np.float32(100.55805), np.float32(2814.0212), np.float32(666.2783), np.float32(3076.4807)], 'confidence': 0.36406001448631287, 'class_id': 66}, {'box': [np.float32(1687.8362), np.float32(932.399), np.float32(1850.1715), np.float32(932.46454)], 'confidence': 0.3632526993751526, 'class_id': 64}, {'box': [np.float32(2321.1274), np.float32(982.796), np.float32(2446.336), np.float32(983.0701)], 'confidence': 0.36307820677757263, 'class_id': 66}, {'box': [np.float32(577.3217), np.float32(2132.7043), np.float32(940.39764), np.float32(2217.541)], 'confidence': 0.363073468208313, 'class_id': 66}, {'box': [np.float32(1503.2572), np.float32(579.5515), np.float32(2013.2391), np.float32(680.39996)], 'confidence': 0.36275479197502136, 'class_id': 66}, {'box': [np.float32(447.91602), np.float32(46.21708), np.float32(575.36096), np.float32(113.60363)], 'confidence': 0.3611515760421753, 'class_id': 66}, {'box': [np.float32(2683.752), np.float32(1744.3887), np.float32(3091.0334), np.float32(1968.1533)], 'confidence': 0.3610284924507141, 'class_id': 66}, {'box': [np.float32(-38.827663), np.float32(980.4239), np.float32(389.77832), np.float32(1118.4048)], 'confidence': 0.3596715033054352, 'class_id': 66}, {'box': [np.float32(2662.0908), np.float32(75.57674), np.float32(2883.5227), np.float32(156.45676)], 'confidence': 0.35505470633506775, 'class_id': 66}, {'box': [np.float32(435.201), np.float32(3400.4224), np.float32(946.4257), np.float32(3402.292)], 'confidence': 0.35355567932128906, 'class_id': 66}, {'box': [np.float32(2296.8408), np.float32(2083.032), np.float32(2777.6973), np.float32(2142.0022)], 'confidence': 0.3524645268917084, 'class_id': 66}]\n"
     ]
    }
   ],
   "source": [
    "original_image = Image.open(\"test.jpg\").convert(\"RGB\")\n",
    "original_size = original_image.size  # (width, height)\n",
    "\n",
    "image_resized = original_image.resize((640, 640))\n",
    "input_data = np.expand_dims(np.array(image_resized, dtype=np.float32), axis=0)\n",
    "def resize_boxes_to_original(results, original_size, input_size=640):\n",
    "    \"\"\"\n",
    "    input_size: 모델 입력 크기 (기본 640)\n",
    "    original_size: (width, height)\n",
    "    \"\"\"\n",
    "    ow, oh = original_size\n",
    "    scale_w = ow / input_size\n",
    "    scale_h = oh / input_size\n",
    "\n",
    "    for det in results:\n",
    "        x1, y1, x2, y2 = det['box']\n",
    "        det['box'] = [\n",
    "            x1 * scale_w,\n",
    "            y1 * scale_h,\n",
    "            x2 * scale_w,\n",
    "            y2 * scale_h\n",
    "        ]\n",
    "    return results\n",
    "\n",
    "results = process_output(output_data, conf_threshold=0.1, iou_threshold=0.5, input_size=640)\n",
    "results = resize_boxes_to_original(results, original_size=(original_image.width, original_image.height))\n",
    "print(results)\n",
    "# 이제 원본 이미지 위에 그릴 수 있음\n",
    "image_bgr = cv2.cvtColor(np.array(original_image), cv2.COLOR_RGB2BGR)\n",
    "output_image = draw_detections(image_bgr.copy(), results)\n",
    "# 결과 보기\n",
    "cv2.imshow(\"Detections\", output_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80cf9265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting roboflow\n",
      "  Downloading roboflow-1.1.66-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: certifi in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from roboflow) (2025.4.26)\n",
      "Collecting idna==3.7 (from roboflow)\n",
      "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: cycler in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from roboflow) (1.4.8)\n",
      "Requirement already satisfied: matplotlib in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from roboflow) (3.10.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from roboflow) (2.1.3)\n",
      "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
      "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from roboflow) (11.1.0)\n",
      "Collecting pillow-heif>=0.18.0 (from roboflow)\n",
      "  Downloading pillow_heif-0.22.0-cp310-cp310-macosx_14_0_arm64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: python-dateutil in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from roboflow) (2.9.0.post0)\n",
      "Collecting python-dotenv (from roboflow)\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: requests in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from roboflow) (2.32.3)\n",
      "Requirement already satisfied: six in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from roboflow) (1.17.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from roboflow) (2.4.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from roboflow) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from roboflow) (6.0.2)\n",
      "Collecting requests-toolbelt (from roboflow)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting filetype (from roboflow)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from matplotlib->roboflow) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from matplotlib->roboflow) (4.57.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from matplotlib->roboflow) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from matplotlib->roboflow) (3.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from requests->roboflow) (3.4.2)\n",
      "Downloading roboflow-1.1.66-py3-none-any.whl (86 kB)\n",
      "Downloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "Downloading opencv_python_headless-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl (54.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow_heif-0.22.0-cp310-cp310-macosx_14_0_arm64.whl (4.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Installing collected packages: filetype, python-dotenv, pillow-heif, opencv-python-headless, idna, requests-toolbelt, roboflow\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.10\n",
      "    Uninstalling idna-3.10:\n",
      "      Successfully uninstalled idna-3.10\n",
      "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pillow-heif-0.22.0 python-dotenv-1.1.0 requests-toolbelt-1.0.0 roboflow-1.1.66\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install roboflow\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c091274c",
   "metadata": {},
   "source": [
    "## 학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caa26c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: roboflow in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (1.1.66)\n",
      "Requirement already satisfied: certifi in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from roboflow) (2025.4.26)\n",
      "Requirement already satisfied: idna==3.7 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from roboflow) (3.7)\n",
      "Requirement already satisfied: cycler in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from roboflow) (1.4.8)\n",
      "Requirement already satisfied: matplotlib in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from roboflow) (3.10.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from roboflow) (2.1.3)\n",
      "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from roboflow) (4.10.0.84)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from roboflow) (11.1.0)\n",
      "Requirement already satisfied: pillow-heif>=0.18.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from roboflow) (0.22.0)\n",
      "Requirement already satisfied: python-dateutil in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from roboflow) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from roboflow) (1.1.0)\n",
      "Requirement already satisfied: requests in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from roboflow) (2.32.3)\n",
      "Requirement already satisfied: six in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from roboflow) (1.17.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from roboflow) (2.4.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from roboflow) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from roboflow) (6.0.2)\n",
      "Requirement already satisfied: requests-toolbelt in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: filetype in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from roboflow) (1.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from matplotlib->roboflow) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from matplotlib->roboflow) (4.57.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from matplotlib->roboflow) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from matplotlib->roboflow) (3.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kimwash/miniforge3/envs/waste-classifier/lib/python3.10/site-packages (from requests->roboflow) (3.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Waste-Detection-and-Classify-2 to yolov11:: 100%|██████████| 268512/268512 [00:39<00:00, 6864.39it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Waste-Detection-and-Classify-2 in yolov11:: 100%|██████████| 16766/16766 [00:03<00:00, 4199.66it/s]\n"
     ]
    }
   ],
   "source": [
    "%pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"lm6P7seuLLTyZkja8jHf\")\n",
    "project = rf.workspace(\"gang-inash\").project(\"waste-detection-and-classify-5rjij\")\n",
    "version = project.version(2)\n",
    "dataset = version.download(\"yolov11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23a19d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e83c779c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.130 🚀 Python-3.10.17 torch-2.6.0 MPS (Apple M1)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/Users/kimwash/Projects/where2throw/model/Waste-Detection-and-Classify-2/data.yaml, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train5, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=5, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    432037  ultralytics.nn.modules.head.Detect           [7, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,591,205 parameters, 2,591,189 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 102.7±22.2 MB/s, size: 32.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/kimwash/Projects/where2throw/model/Waste-Detection-and-Classify-2/train/labels.cache... 8312 images, 52 backgrounds, 0 corrupt: 100%|██████████| 8312/8312 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 14, len(boxes) = 15804. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 158.1±80.4 MB/s, size: 30.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/kimwash/Projects/where2throw/model/Waste-Detection-and-Classify-2/valid/labels.cache... 39 images, 0 backgrounds, 0 corrupt: 100%|██████████| 39/39 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train5/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train5\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/520 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolo11n.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWaste-Detection-and-Classify-2/data.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Export the model to TFLite format\u001b[39;00m\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mexport(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoreml\u001b[39m\u001b[38;5;124m\"\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m'\u001b[39m, nms\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# creates 'yolo11n CoreML Model'\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/waste-classifier/lib/python3.10/site-packages/ultralytics/engine/model.py:793\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m    792\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 793\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[0;32m~/miniforge3/envs/waste-classifier/lib/python3.10/site-packages/ultralytics/engine/trainer.py:212\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    209\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/waste-classifier/lib/python3.10/site-packages/ultralytics/engine/trainer.py:399\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;66;03m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ni \u001b[38;5;241m-\u001b[39m last_opt_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccumulate:\n\u001b[0;32m--> 399\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m     last_opt_step \u001b[38;5;241m=\u001b[39m ni\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;66;03m# Timed stopping\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/waste-classifier/lib/python3.10/site-packages/ultralytics/engine/trainer.py:619\u001b[0m, in \u001b[0;36mBaseTrainer.optimizer_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39munscale_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer)  \u001b[38;5;66;03m# unscale gradients\u001b[39;00m\n\u001b[1;32m    618\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10.0\u001b[39m)  \u001b[38;5;66;03m# clip gradients\u001b[39;00m\n\u001b[0;32m--> 619\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniforge3/envs/waste-classifier/lib/python3.10/site-packages/torch/amp/grad_scaler.py:380\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke ``unscale_(optimizer)`` followed by parameter update, if gradients are not infs/NaN.\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \n\u001b[1;32m    360\u001b[0m \u001b[38;5;124;03m:meth:`step` carries out the following two operations:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;124;03m    Closure use is not currently supported.\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enabled:\n\u001b[0;32m--> 380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosure\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    384\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClosure use is not currently supported if GradScaler is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    385\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/waste-classifier/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:140\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m opt \u001b[38;5;241m=\u001b[39m opt_ref()\n\u001b[1;32m    139\u001b[0m opt\u001b[38;5;241m.\u001b[39m_opt_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/waste-classifier/lib/python3.10/site-packages/torch/optim/optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    490\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 493\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/waste-classifier/lib/python3.10/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/miniforge3/envs/waste-classifier/lib/python3.10/site-packages/torch/optim/adamw.py:243\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    230\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m cast(Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m], group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    232\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    233\u001b[0m         group,\n\u001b[1;32m    234\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    240\u001b[0m         state_steps,\n\u001b[1;32m    241\u001b[0m     )\n\u001b[0;32m--> 243\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniforge3/envs/waste-classifier/lib/python3.10/site-packages/torch/optim/optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/waste-classifier/lib/python3.10/site-packages/torch/optim/adamw.py:875\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 875\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/waste-classifier/lib/python3.10/site-packages/torch/optim/adamw.py:477\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    475\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 477\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    479\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# Load the YOLO11 model\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "path = os.path.abspath(\"Waste-Detection-and-Classify-2/data.yaml\")\n",
    "model.train(data=path,epochs=30,patience=5,imgsz=640, device=\"mps\")\n",
    "\n",
    "# Export the model to TFLite format\n",
    "model.export(format=\"coreml\", device='mps', nms=True)  # creates 'yolo11n CoreML Model'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "waste-classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
